\section{Finding Periodic Solutions}
\label{sec:initial}

A separate problem from evaluating, optimizing and continuing periodic solutions is finding an initial candidate solution.
Because continuation is a crucial part of this project, having just one single periodic solution might enable to find many others, through tracing and switching solution branches.
Because the systems considered in this work have stable periodic solutions, we focus on this case.
When this is not the case, as mentioned in the section about continuation methods (\autoref{sec:cont}), a homotopy between a trivial system and the target system, combined with continuation methods, might be a promising approach.

Starting from a point in the periodic solution's basin of attraction, one can simply forward integrate such a system.
There are several possible problems involved:
\begin{itemize}
	\item Forward integration can accumulate errors.
	\item Even if the starting point lies exactly on the periodic trajectory, the sampling interval would probably not be an integer fraction of the period of the periodic trajectory.
		Periodicity in the sequence of points are not directly related to periodicity in the continuous system.
	\item Given the nature of the project, it is very likely that period doubling bifurcations are encountered.
		These provoke situations where two periodic solutions exist which are difficult to distinguish.
\end{itemize}

Forward integration yields a sequence of points in phase space $(\textbf{s}_i)_{i \in \N}$.
To obtain more manageable data only intersections of the trajectory with a hyperplane $p(\textbf{x}) = \langle \textbf{n}, \textbf{x}-\textbf{x}_0 \rangle = 0$ in a single direction are considered (so called Poincar√© sections).
To find these, $\textbf{s}_i, \textbf{s}_{i+1} = \textbf{s}_i + h_0 \cdot \textbf{f}(\textbf{s}_i)$ with $p(s_i) \le 0 < p(s_{i+1})$ are searched.
Because of continuity, there needs to exists $h \in [0,h_0]$ such that $p(\textbf{s}_i + h \cdot \textbf{f}(\textbf{s}_i)) = 0$, which is found via bisection.
Let $(\textbf{u}_i)_{i \in \N}$ be the sequence of intersections.

To find the number of intersections per period, the intersections are partitioned into $k \in \N$ disjoint clusters $V_{k,i} = \{ \textbf{u}_m\ |\ m \in k\N+i \}$ for $i \in \N$, $i \le k$.
The relative quality of the $i$-th cluster can then be assessed using the within-cluster variance $\sum_{v \in V_{k,i} } ||v - \E(V_{k,i})||^2$.
The correct number $k_{\text{min}} \in \N$ of intersections in one period is then taken to be the one minimizing the sum of within-cluster variances:
\[
	k_\text{min} \coloneqq \argmin_{k \in \N} \sum_{i = 1}^k \sum_{v \in V_{k,i} } ||v - \E(V_{k,i})||^2 \text.
\]
For further information about these measures see for example \cite{halkidi2001clustering}. %TODO measure...

In this form the criterion might at best work if the intersection sequence is infinite.
When dealing with finite sequences increasing the number of clusters inevitably leads to lower total within-cluster variances.
It is thus necessary to constrain the available values for $k$ and discourage the method of overestimating the number of clusters.
Trivially an upper limit for $k$ needs to be introduced.
Furthermore, the minimality criterion needs to be relaxed: Suppose there are $k_\text{min}$ intersections per period, then all multiples of $k_\text{min}$ yield equal or lower ratings.
One thus wants to choose the minimum $k$ which is in some sense still almost optimal.
